{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZhptaNBswwF",
        "outputId": "2d2043f5-4684-4459-fc52-c0f1e5ca88d3"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import drive \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edSwhzMItGR5",
        "outputId": "1eaff3e9-9833-43f6-c6d7-764d99a1c2fe"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgaiHhUqs8_S"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "h_bodAHAtQQZ",
        "outputId": "696358fe-6048-492e-960d-bfed32b1c87c"
      },
      "source": [
        "df = pd.read_csv('gdrive/MyDrive/text_pre_processing.csv', sep=',')\n",
        "df.head(5)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "      <th>caps_in_title</th>\n",
              "      <th>text_tokens</th>\n",
              "      <th>text_urls</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>title_urls</th>\n",
              "      <th>twitter_handles</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>clean_text_tokens</th>\n",
              "      <th>clean_title_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-31</td>\n",
              "      <td>fake</td>\n",
              "      <td>11</td>\n",
              "      <td>['Donald', 'Trump', 'just', 'couldn', 't', 'wi...</td>\n",
              "      <td>['pic.twitter.com/4FPAe2KypA']</td>\n",
              "      <td>donald trump just couldn t wish all americans ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@realDonaldTrump', '@TalbertSwan', '@calvins...</td>\n",
              "      <td>donald trump sends out embarrassing new year’s...</td>\n",
              "      <td>['donald', 'trump', 'just', 'couldn', 'wish', ...</td>\n",
              "      <td>['donald', 'trump', 'sends', 'out', 'embarrass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-31</td>\n",
              "      <td>fake</td>\n",
              "      <td>8</td>\n",
              "      <td>['House', 'Intelligence', 'Committee', 'Chairm...</td>\n",
              "      <td>[]</td>\n",
              "      <td>house intelligence committee chairman devin nu...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>drunk bragging trump staffer started russian c...</td>\n",
              "      <td>['house', 'intelligence', 'committee', 'chairm...</td>\n",
              "      <td>['drunk', 'bragging', 'trump', 'staffer', 'sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-30</td>\n",
              "      <td>fake</td>\n",
              "      <td>15</td>\n",
              "      <td>['On', 'Friday', 'it', 'was', 'revealed', 'tha...</td>\n",
              "      <td>['pic.twitter.com/XtZW5PdU2b', 'pic.twitter.co...</td>\n",
              "      <td>on friday, it was revealed that former milwauk...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@SheriffClarke', '@SheriffClarke', '@KeithLe...</td>\n",
              "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
              "      <td>['on', 'it', 'was', 'revealed', 'that', 'forme...</td>\n",
              "      <td>['sheriff', 'david', 'clarke', 'becomes', 'an'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-29</td>\n",
              "      <td>fake</td>\n",
              "      <td>19</td>\n",
              "      <td>['On', 'Christmas', 'day', 'Donald', 'Trump', ...</td>\n",
              "      <td>['https://t.co/Fg7VacxRtJ', 'pic.twitter.com/5...</td>\n",
              "      <td>on christmas day, donald trump announced that ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@pbump', '@_cingraham', '@_cingraham', '@_ci...</td>\n",
              "      <td>trump is so obsessed he even has obama’s name ...</td>\n",
              "      <td>['on', 'christmas', 'day', 'donald', 'trump', ...</td>\n",
              "      <td>['trump', 'is', 'so', 'obsessed', 'he', 'even'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-25</td>\n",
              "      <td>fake</td>\n",
              "      <td>11</td>\n",
              "      <td>['Pope', 'Francis', 'used', 'his', 'annual', '...</td>\n",
              "      <td>[]</td>\n",
              "      <td>pope francis used his annual christmas day mes...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>pope francis just called out donald trump duri...</td>\n",
              "      <td>['pope', 'francis', 'used', 'his', 'annual', '...</td>\n",
              "      <td>['pope', 'francis', 'just', 'called', 'out', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                 clean_title_tokens\n",
              "0           0  ...  ['donald', 'trump', 'sends', 'out', 'embarrass...\n",
              "1           1  ...  ['drunk', 'bragging', 'trump', 'staffer', 'sta...\n",
              "2           2  ...  ['sheriff', 'david', 'clarke', 'becomes', 'an'...\n",
              "3           3  ...  ['trump', 'is', 'so', 'obsessed', 'he', 'even'...\n",
              "4           4  ...  ['pope', 'francis', 'just', 'called', 'out', '...\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bmxl5ff2tUOK",
        "outputId": "9c4ae4bd-decb-4b78-c9c0-858dbc19ccf2"
      },
      "source": [
        "df = df.drop(['Unnamed: 0'], axis = 1)\n",
        "df = df.drop(['Unnamed: 0.1'], axis = 1)\n",
        "df = df.drop(['text_tokens'], axis = 1)\n",
        "df = df.drop(['text_urls'], axis = 1)\n",
        "df = df.drop(['title_urls'], axis = 1)\n",
        "df = df.drop(['twitter_handles'], axis = 1)\n",
        "df = df.drop(['clean_text_tokens'], axis = 1)\n",
        "df = df.drop(['clean_title_tokens'], axis = 1)\n",
        "df.head(5)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "      <th>caps_in_title</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>clean_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-31</td>\n",
              "      <td>fake</td>\n",
              "      <td>11</td>\n",
              "      <td>donald trump just couldn t wish all americans ...</td>\n",
              "      <td>donald trump sends out embarrassing new year’s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-31</td>\n",
              "      <td>fake</td>\n",
              "      <td>8</td>\n",
              "      <td>house intelligence committee chairman devin nu...</td>\n",
              "      <td>drunk bragging trump staffer started russian c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-30</td>\n",
              "      <td>fake</td>\n",
              "      <td>15</td>\n",
              "      <td>on friday, it was revealed that former milwauk...</td>\n",
              "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-29</td>\n",
              "      <td>fake</td>\n",
              "      <td>19</td>\n",
              "      <td>on christmas day, donald trump announced that ...</td>\n",
              "      <td>trump is so obsessed he even has obama’s name ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>2017-12-25</td>\n",
              "      <td>fake</td>\n",
              "      <td>11</td>\n",
              "      <td>pope francis used his annual christmas day mes...</td>\n",
              "      <td>pope francis just called out donald trump duri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...                                        clean_title\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...  ...  donald trump sends out embarrassing new year’s...\n",
              "1   Drunk Bragging Trump Staffer Started Russian ...  ...  drunk bragging trump staffer started russian c...\n",
              "2   Sheriff David Clarke Becomes An Internet Joke...  ...  sheriff david clarke becomes an internet joke ...\n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...  ...  trump is so obsessed he even has obama’s name ...\n",
              "4   Pope Francis Just Called Out Donald Trump Dur...  ...  pope francis just called out donald trump duri...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nkz9EcatnZD"
      },
      "source": [
        "#add the target column\n",
        "df['Target'] = df['label'].apply(lambda x: 'True' if x == True else 'False')"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GncPcvmttp8d"
      },
      "source": [
        "#The Target column is made of strings, and it is not computer-friendly. So we adjust it\n",
        "df['label']=pd.get_dummies(df.Target)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXx4aSK1tq-5"
      },
      "source": [
        "Text Classification using Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4M2aUgDts3p"
      },
      "source": [
        "#1.Train-Validation split\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['clean_title'],df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.25, \n",
        "                                                                    stratify=df['Target'])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnCrmlxQtwvj"
      },
      "source": [
        "#2.Validation-Test split\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.15, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70YfwEfq00Of"
      },
      "source": [
        "So, we will fine-tune the model using the train set and the validation set, and make predictions for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipShfy0stzZM",
        "outputId": "34da70ec-ebb6-4896-8063-a8bc94b8e9f4"
      },
      "source": [
        "#3.Defining the model and the tokenizer of BERT.\n",
        "\n",
        "#import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saSjsteBt2Us"
      },
      "source": [
        "#plot style\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['font.family'] = 'sans-serif' \n",
        "plt.rcParams['font.serif'] = 'Ubuntu' \n",
        "plt.rcParams['font.monospace'] = 'Ubuntu Mono' \n",
        "plt.rcParams['font.size'] = 14 \n",
        "plt.rcParams['axes.labelsize'] = 12 \n",
        "plt.rcParams['axes.labelweight'] = 'bold' \n",
        "plt.rcParams['axes.titlesize'] = 12 \n",
        "plt.rcParams['xtick.labelsize'] = 12 \n",
        "plt.rcParams['ytick.labelsize'] = 12 \n",
        "plt.rcParams['legend.fontsize'] = 12 \n",
        "plt.rcParams['figure.titlesize'] = 12 \n",
        "plt.rcParams['image.cmap'] = 'jet' \n",
        "plt.rcParams['image.interpolation'] = 'none' \n",
        "plt.rcParams['figure.figsize'] = (10, 10\n",
        "                                 ) \n",
        "plt.rcParams['axes.grid']=False\n",
        "plt.rcParams['lines.linewidth'] = 2 \n",
        "plt.rcParams['lines.markersize'] = 8\n",
        "colors = ['xkcd:pale range', 'xkcd:sea blue', 'xkcd:pale red', 'xkcd:sage green', 'xkcd:terra cotta', 'xkcd:dull purple', 'xkcd:teal', 'xkcd: goldenrod', 'xkcd:cadet blue',\n",
        "'xkcd:scarlet']"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "kAxY3KWCt5Mt",
        "outputId": "047bf1be-eac1-45c1-897f-1747788198dd"
      },
      "source": [
        "#4.Plotting the histogram\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 40,color='firebrick')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Number of texts')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Number of texts')"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndm21uABt-v8"
      },
      "source": [
        "Since the text in the dataset are of varying length, therefore we will use padding to make all the messages have the same length. We can use the maximum sequence length to pad the messages. However, using the previous histogram we find the righ padding lenght. We will use the max lenght equal to the mean of words in a title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2lYPm9uByF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7183992f-ba24-419b-8dc5-5d1ec2ca2213"
      },
      "source": [
        "import statistics\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "MAX_LENGHT = int(statistics.mean(seq_len))\n",
        "print(MAX_LENGHT)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hwHiT5bt_gT",
        "outputId": "ebb79f18-8e39-413c-833b-1d67f20e0929"
      },
      "source": [
        "#MAX_LENGHT = 399\n",
        "\n",
        "#tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = MAX_LENGHT,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = MAX_LENGHT,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = MAX_LENGHT,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOFE8IBkuD27"
      },
      "source": [
        "#5.Converting lists to tensors\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist()) "
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkoFUmOy77tz"
      },
      "source": [
        "Now we will create dataloaders for both train and validation set. These dataloaders will pass batches of train data and validation data as input to the model during the training phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14z9O5koucMg"
      },
      "source": [
        "#6.Data Loader structure definition:\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0RME0U58D7M"
      },
      "source": [
        "Define Model Architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDyY6ojIujeq"
      },
      "source": [
        "#7.Freezing the parameters and defining the trainable BERT structure:\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMeho3fv8Ls8"
      },
      "source": [
        "We freeze all the layers of the model before fine-tuning it. This will prevent updating of model weights during fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtLk4gyvupnk"
      },
      "source": [
        "#define our model architecture.\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']\n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpqqM4yqu2SM"
      },
      "source": [
        "model = BERT_Arch(bert)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOUNvv2h8kaL"
      },
      "source": [
        "We will use AdamW as our optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC3rt5GEu5Ar"
      },
      "source": [
        "#8.Defining the hyperparameters (optimizer, weights of the classes and the epochs)\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5)          # learning rate"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTjWyCTQvC48",
        "outputId": "eb061bb9-8383-430b-ba80-62afcbeee4a9"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [3.29145843 0.58955892]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlIBweKbvM32"
      },
      "source": [
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0yKhJE19Cem"
      },
      "source": [
        "Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu7xDnGYvP8a"
      },
      "source": [
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r for r in batch]\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq6RoqUpvXWz"
      },
      "source": [
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "       \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mno_ffWIvarT",
        "outputId": "d030d578-0a25-4629-f56d-1adf6eba196c"
      },
      "source": [
        "# Train and predict\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.654\n",
            "Validation Loss: 0.613\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.606\n",
            "Validation Loss: 0.579\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.572\n",
            "Validation Loss: 0.539\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.545\n",
            "Validation Loss: 0.511\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.520\n",
            "Validation Loss: 0.492\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.502\n",
            "Validation Loss: 0.470\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.484\n",
            "Validation Loss: 0.455\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.472\n",
            "Validation Loss: 0.446\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.463\n",
            "Validation Loss: 0.439\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of    906.\n",
            "  Batch   100  of    906.\n",
            "  Batch   150  of    906.\n",
            "  Batch   200  of    906.\n",
            "  Batch   250  of    906.\n",
            "  Batch   300  of    906.\n",
            "  Batch   350  of    906.\n",
            "  Batch   400  of    906.\n",
            "  Batch   450  of    906.\n",
            "  Batch   500  of    906.\n",
            "  Batch   550  of    906.\n",
            "  Batch   600  of    906.\n",
            "  Batch   650  of    906.\n",
            "  Batch   700  of    906.\n",
            "  Batch   750  of    906.\n",
            "  Batch   800  of    906.\n",
            "  Batch   850  of    906.\n",
            "  Batch   900  of    906.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    257.\n",
            "  Batch   100  of    257.\n",
            "  Batch   150  of    257.\n",
            "  Batch   200  of    257.\n",
            "  Batch   250  of    257.\n",
            "\n",
            "Training Loss: 0.451\n",
            "Validation Loss: 0.428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGYTJolN-tIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ed1614-e491-4f2b-9718-6c51ff668f5d"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hiZHuBK-x_L"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUZtpR2DMd3E"
      },
      "source": [
        "We will evaluate the model using the classificationr eport, confusion amtrix and the Precision Recall Curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eNaolNa-t7D"
      },
      "source": [
        "with torch.no_grad():\n",
        "    preds = model(test_seq, test_mask)\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxH7YBNF-wAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a1a6a4-f8cc-4800-c643-6fd8d171b6a7"
      },
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.84      0.57       220\n",
            "           1       0.97      0.80      0.88      1229\n",
            "\n",
            "    accuracy                           0.81      1449\n",
            "   macro avg       0.70      0.82      0.73      1449\n",
            "weighted avg       0.89      0.81      0.83      1449\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_O73eqJ-ztM"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSZ0UrFB-10Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "26d07c39-a4f7-4f56-f4ef-2c846274643a"
      },
      "source": [
        "conf_mat = confusion_matrix(y_true=test_y, y_pred=preds,labels =[0, 1])\n",
        "pd.DataFrame(conf_mat, columns = [0,1],index = [0, 1])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>185</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>241</td>\n",
              "      <td>988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1\n",
              "0  185   35\n",
              "1  241  988"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXoM9-Bo-5bN"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc3ivWk8-7Hd"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX-BB9lr-9P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e802dcf-5d82-4df7-e7e3-7d602389901b"
      },
      "source": [
        "device"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Qit6Vd-_DW"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccROuvtn_BHE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "ce88faf0-5c86-4143-f3b5-811124970260"
      },
      "source": [
        "# model's performance\n",
        "precision_, recall_, proba = precision_recall_curve(test_y, preds[:, -1])\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "#plot precision-recall curve\n",
        "plt.plot(recall_, precision_, marker='.', label='BERT-model')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}